#!/usr/bin/env python3

# Watches the log files generated by SyncFrameLogger.  Prints a feed of 
# the non-nan values for the provided sensor index (first argument) 

'''
Some notes on sync frames, which replaced omnilog files to better align
with the needs of the main TIME MCE data acquisition system by providing
organized time streams of HK sensors at the detector frame rate.

Each sync frame file is simply a numpy array containing the values of
an array of sensors for a group of 100 MCE sync numbers.  Because MCE
sync numbers update at 100 Hz, this means there is usually 1 file per
second.  For example, a file /data/hk/syncframes/syncframes.12192400.npy
would contain the values for all of the specified sensors at MCE sync
numbers 12192400, 12192401, ..., 12192499.  None of the sensors are read
out at 100 Hz, so most of the entries in the matrix are NaNs.  Not all
sensors are automatically included in the sync frames, and not all
hardware is capable of reporting in MCE sync numbers.  I have it set to
report up to 256 sensors (so you get an array of size (100, 256) per
second), but this can be changed as needed.  You can choose which of the
sensors get stored in which index in the hw_time.json5 config file.
Old sync frames will be deleted automatically by pyhk.  All sensor
values are still stored in the traditional pyhk data files and are not
lost, regardless of what happens with sync frames.  I have the IRIG 
epoch time reported by the two HK boxes as sensors 0 and 1 (they should
be equal and are redundant).  This is the (sync num, NTP time) pair you
need to register telescope data to detector data in TIME.
'''

import sys
import os
import glob
import time
import numpy as np

SYNC_FILE_PATTERN = '/data/hk/syncframes/syncframes.*.npy'

# Get the file name of the second newest sync frame (the newest one
# may still be being written to)
def next_sync_file():
	
	# Get a list of all of the sync frame files and their creation times
	file_names = [f for f in glob.glob(SYNC_FILE_PATTERN)]
	file_ctimes = []
	for f in file_names:
		try:
			file_ctimes.append(os.path.getctime(f))
		except FileNotFoundError:
			# Files are always being deleted, so we have to assume the
			# old file might be gone before we read its ctime
			file_ctimes.append(0)
	assert len(file_names) == len(file_ctimes)
	assert len(file_ctimes) >= 2, "Not enough sync frames found to start processing"
	
	# Load the second newest file, since the newest file may still be
	# being written to
	file_index = np.argsort(file_ctimes)[-2]
	file_name = file_names[file_index]
	
	return file_name
	
	
if __name__ == "__main__":
	
	if len(sys.argv) < 2:
		sys.exit("Provide the sensor index as an argument when you call the script")
		
	print("Printing finite values only for user sanity")

	sensor_index = int(sys.argv[1])
	last_file_read = None
	
	while True:
		try:
			# Rate limit checks to ~20 Hz 
			time.sleep(1.0/20)
			
			# Grab the (2nd) newest file
			file_name = next_sync_file()
			
			# Don't reread files
			if file_name == last_file_read:
				continue
			
			# Pull the base sync number for this frame out of the file
			# name.  Sync number indices in this frame will be relative
			# to this base number (N+0, N+1, ..., N+99)
			sync_num_base = int(file_name.split('.')[-2])
			
			# Load in the array indexed (sync_num_offset, sensor_index), 
			# usually with shape (100, 256)
			try:
				data = np.load(file_name)
				last_file_read = file_name
			except FileNotFoundError:
				print("Failed loading " + file_name)
				continue
			
			assert sensor_index < data.shape[1], "Sensor index is out of range!"

			# Iterate over sync frames, report any that are finite for the
			# sensor index we are watching
			for sync_num_offset in range(data.shape[0]):
				sensor_value = data[sync_num_offset][sensor_index]
				if np.isfinite(sensor_value):
					sync_num = sync_num_base + sync_num_offset
					print("file: %i\tsync: %i\tvalue: %s" % (sync_num_base, sync_num, sensor_value))
			 
		except KeyboardInterrupt:
			break
			
	print("Exiting")
